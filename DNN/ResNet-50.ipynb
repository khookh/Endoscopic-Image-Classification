{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import custom_layers\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "PATH_KVASIR = 'E:\\\\Gastroscopies\\\\hyper_kvasir\\\\upper-gi-tract\\\\anatomical-landmarks'\n",
    "MODEL_PATH = 'MODEL_RESNET50'\n",
    "batch_size = 32\n",
    "LR = 0.00005\n",
    "img_height = 500\n",
    "img_width = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 12s 0us/step\n",
      "94781440/94765736 [==============================] - 12s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# load pre-trained (imagenet) ResNet50 model\n",
    "ResNet50 = tf.keras.applications.resnet50.ResNet50(include_top=False, weights='imagenet', input_shape =(img_height, img_width, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(ResNet50 , to_file='InceptionV3.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2695 files belonging to 3 classes.\n",
      "Using 2426 files for training.\n",
      "Found 2695 files belonging to 3 classes.\n",
      "Using 269 files for validation.\n",
      "['pylorus', 'retroflex-stomach', 'z-line']\n"
     ]
    }
   ],
   "source": [
    "kvasir_dir = pathlib.Path(PATH_KVASIR)\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    kvasir_dir,\n",
    "    validation_split=0.1,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    kvasir_dir,\n",
    "    validation_split=0.1,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "labels = train_ds.class_names\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip('vertical'),\n",
    "    custom_layers.Random90Rotation(),\n",
    "    custom_layers.RandomHue(),\n",
    "    #custom_layers.RandomGaussian()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_and_rescale = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.Resizing(img_height, img_width),\n",
    "  tf.keras.layers.experimental.preprocessing.Rescaling(scale=1./127.5, offset=-1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_end = tf.keras.Sequential([\n",
    "    # https://www.pluralsight.com/guides/introduction-to-densenet-with-tensorflow\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(1024,activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(512,activation=\"relu\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.3)\n",
    "])\n",
    "\n",
    "prediction_layer = tf.keras.layers.Dense(3,activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 500, 500, 3)]     0         \n",
      "_________________________________________________________________\n",
      "sequential_5 (Sequential)    (None, 500, 500, 3)       0         \n",
      "_________________________________________________________________\n",
      "sequential_6 (Sequential)    (None, 500, 500, 3)       0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, 16, 16, 2048)      23587712  \n",
      "_________________________________________________________________\n",
      "sequential_7 (Sequential)    (None, 512)               2633216   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 26,222,467\n",
      "Trainable params: 2,629,635\n",
      "Non-trainable params: 23,592,832\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(img_height, img_width, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = resize_and_rescale(x)\n",
    "x = ResNet50(x)\n",
    "x = dense_end(x)\n",
    "outputs = prediction_layer(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# initially freeze DenseNet to avoid overfitting, will unfreeze during fine-tuning \n",
    "for layer in model.layers[:-2]:\n",
    "    layer.trainable=False \n",
    "    \n",
    "for layer in model.layers[-2:]:\n",
    "    layer.trainable=True\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=LR),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### TEST UNTRAINED MODEL ###\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_batch, label_batch = next(iter(train_ds))\n",
    "pred = model.predict(image_batch)\n",
    "\n",
    "source = image_batch[0].numpy()/255\n",
    "index_pred = np.argmax(pred[0])\n",
    "index_real = label_batch[0]\n",
    "\n",
    "plt.imshow(source)\n",
    "plt.title(\"pred-> \" + labels[index_pred]+\" | real->\" + labels[index_real])\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines fit callbacks\n",
    "checkpoint =  tf.keras.callbacks.ModelCheckpoint(MODEL_PATH, monitor='val_loss',save_weights_only=True, save_best_only=True)\n",
    "early =  tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=5, verbose=1)\n",
    "plateau = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,\n",
    "                              patience=2, min_lr=LR/10,cooldown=3, verbose=1)\n",
    "fit_callbacks = [checkpoint,early,plateau]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_start = model.fit(\n",
    "    train_ds,\n",
    "    epochs=8,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=fit_callbacks\n",
    ")\n",
    "\n",
    "for layer in model.layers[:-2]:\n",
    "    layer.trainable=True\n",
    "    \n",
    "history_fine_tuning = model.fit(\n",
    "    train_ds,\n",
    "    epochs=5,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=fit_callbacks\n",
    ")\n",
    "\n",
    "for layer in model.layers[:-2]:\n",
    "    layer.trainable=False\n",
    "\n",
    "history_end = model.fit(\n",
    "    train_ds,\n",
    "    epochs=4,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=fit_callbacks\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training Plots ###\n",
    "acc = history_start.history['accuracy']\n",
    "val_acc = history_start.history['val_accuracy']\n",
    "loss = history_start.history['loss']\n",
    "val_loss = history_start.history['val_loss']\n",
    "\n",
    "acc = np.hstack([acc,history_fine_tuning.history['accuracy']])\n",
    "val_acc = np.hstack([val_acc,history_fine_tuning.history['val_accuracy']])\n",
    "loss = np.hstack([loss,history_fine_tuning.history['loss']])\n",
    "val_loss = np.hstack([val_loss,history_fine_tuning.history['val_loss']])\n",
    "\n",
    "acc = np.hstack([acc,history_end.history['accuracy']])\n",
    "val_acc = np.hstack([val_acc,history_end.history['val_accuracy']])\n",
    "loss = np.hstack([loss,history_end.history['loss']])\n",
    "val_loss = np.hstack([val_loss,history_end.history['val_loss']])\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### model evaluation ###\n",
    "#model = tf.keras.models.load_model(MODEL_PATH)\n",
    "model.evaluate(val_ds)\n",
    "#model.save(MODEL_PATH)\n",
    "\n",
    "validation_iterator = iter(val_ds)\n",
    "pred_label = np.array([])\n",
    "true_label = np.array([])\n",
    "while True:\n",
    "    image_batch, label_batch = validation_iterator.get_next()\n",
    "    pred_label = np.append(pred_label,model.predict(image_batch).argmax(1))\n",
    "    true_label = np.append(true_label,label_batch)\n",
    "    if len(image_batch) != batch_size : \n",
    "        break\n",
    "        \n",
    "pred_label = np.array([labels[int(x)] for x in pred_label])\n",
    "true_label = np.array([labels[int(x)] for x in true_label])\n",
    "\n",
    "cm = confusion_matrix(true_label, pred_label, normalize='true')\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax);  \n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(labels); ax.yaxis.set_ticklabels(labels);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXAMPLE TRAINED MODEL ###\n",
    "\n",
    "image_batch, label_batch = next(iter(train_ds))\n",
    "pred = model.predict(image_batch)\n",
    "\n",
    "rows, columns = 8, 4\n",
    "\n",
    "fig = plt.figure(figsize=(30, 50))\n",
    "for i in range(len(image_batch)):\n",
    "    fig.add_subplot(rows,columns, i+1)\n",
    "    \n",
    "    source = image_batch[i].numpy()/255\n",
    "    index_pred = np.argmax(pred[i])\n",
    "    index_real = label_batch[i]\n",
    "\n",
    "    plt.imshow(source)\n",
    "    plt.title(\"pred-> \" + labels[index_pred]+\" | real->\" + labels[index_real])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### model evaluation failures ###\n",
    "\n",
    "fig = plt.figure(figsize=(30, 50))\n",
    "rows, columns = 8, 4\n",
    "validation_iterator = iter(val_ds)\n",
    "pred_label = np.array([])\n",
    "true_label = np.array([])\n",
    "i = 0\n",
    "j = 0\n",
    "while True:\n",
    "    image_batch, label_batch = validation_iterator.get_next()\n",
    "    pred = model.predict(image_batch)\n",
    "    index_pred = np.argmax(pred[i])\n",
    "    index_real = label_batch[i]\n",
    "    if len(image_batch) != batch_size : \n",
    "        break\n",
    "    for k in range(len(image_batch)):\n",
    "        source = image_batch[k].numpy()/255\n",
    "        index_pred = np.argmax(pred[k])\n",
    "        index_real = label_batch[k]\n",
    "        if index_pred != index_real:\n",
    "            fig.add_subplot(rows,columns,j+1)\n",
    "            plt.imshow(source)\n",
    "            plt.title(\"pred-> \" + labels[index_pred]+\" | real->\" + labels[index_real])\n",
    "            plt.axis(\"off\")\n",
    "            j+=1\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test on study set ###\n",
    "\n",
    "PATH_ETUDE = 'E:\\\\Gastroscopies\\\\Etude\\\\Train'\n",
    "\n",
    "etude_dir = pathlib.Path(PATH_ETUDE)\n",
    "\n",
    "etude_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    etude_dir,\n",
    "    validation_split=0.05,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "etude_ds = etude_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "\n",
    "model.evaluate(etude_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### model evaluation failures STUDY_DIR ###\n",
    "\n",
    "fig = plt.figure(figsize=(30, 50))\n",
    "rows, columns = 8, 4\n",
    "validation_iterator = iter(etude_ds)\n",
    "pred_label = np.array([])\n",
    "true_label = np.array([])\n",
    "i = 0\n",
    "j = 0\n",
    "while True:\n",
    "    image_batch, label_batch = validation_iterator.get_next()\n",
    "    pred = model.predict(image_batch)\n",
    "    index_pred = np.argmax(pred[i])\n",
    "    index_real = label_batch[i]\n",
    "    if len(image_batch) != batch_size : \n",
    "        break\n",
    "    for k in range(len(image_batch)):\n",
    "        source = image_batch[k].numpy()/255\n",
    "        index_pred = np.argmax(pred[k])\n",
    "        index_real = label_batch[k]\n",
    "        if index_pred != index_real:\n",
    "            fig.add_subplot(rows,columns,j+1)\n",
    "            plt.imshow(source)\n",
    "            plt.title(\"pred-> \" + labels[index_pred]+\" | real->\" + labels[index_real])\n",
    "            plt.axis(\"off\")\n",
    "            j+=1\n",
    "    i+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
